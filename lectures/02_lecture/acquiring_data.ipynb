{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Acquiring Data\n",
    "\n",
    "Most analyses start by importing data into your environment. The data are primarily available from the following data sources:\n",
    "\n",
    "- Local files (you should already have an idea)\n",
    "- Databases\n",
    "- APIs\n",
    "\n",
    "> ✏️ The example is inspired by {cite}`reid_2021`.\n",
    "\n",
    "Luckily for us, Python is very capable when accessing all of those data sources because there are tons of open-source libraries. Once we have access, we can easily import data to NumPy, pandas, or other libraries to exploit what we have learned regarding data wrangling. We will show you some basic examples to give you an idea.\n",
    "\n",
    "We have been primarily working with local files (CSV) so far, but a lot of business data is probably stored in a database. You usually need to know some basics of SQL (which is out of the scope of this course) to access the data.\n",
    "\n",
    "It is pretty easy to get data from a database to pandas. Let's use, for example, a built-in database SQLite with the [Chinook Dataset](https://github.com/lerocha/chinook-database):"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# TODO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Connecting to an API might be a bit more challenging. The basic idea is to send a request (which may include query parameters and access credentials) to an endpoint, which will return a response code plus the data you asked for. Let's try it on a simple example:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# TODO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, let's review some sources with valuable datasets that might help you with your projects. We will list just a few tips to get you started:\n",
    "\n",
    "- Kaggle is known for hosting machine learning and deep learning challenges, and with those challenges also come datasets.\n",
    "- .gov Datasets - many countries openly share their datasets with the public.\n",
    "- UCI Machine Learning Repository provides easy-to-use and cleaned datasets. We are also using some of their datasets during our lectures.\n",
    "- Dataset Subreddits might be another great source of data. People usually discuss the available datasets and how to use existing datasets for new tasks.\n",
    "- Another excellent community-driven source is [Awesome Public Datasets](https://github.com/awesomedata/awesome-public-datasets) on GitHub and its forks\n",
    "\n",
    "## Resources\n",
    "\n",
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
